{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.feature_selection import SelectKBest, VarianceThreshold\n",
    "from sklearn.feature_selection import mutual_info_regression, f_regression\n",
    "from sklearn import preprocessing\n",
    "from sklearn import decomposition\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF,DotProduct, ConstantKernel,WhiteKernel,Matern,RationalQuadratic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "## 1. Read data from csv file\n",
    "Use pandas to read csv file. Then discard unnecessary columns (id column). Check the correctness of data reading in the end of the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x822</th>\n",
       "      <th>x823</th>\n",
       "      <th>x824</th>\n",
       "      <th>x825</th>\n",
       "      <th>x826</th>\n",
       "      <th>x827</th>\n",
       "      <th>x828</th>\n",
       "      <th>x829</th>\n",
       "      <th>x830</th>\n",
       "      <th>x831</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10.891876</td>\n",
       "      <td>832442.812375</td>\n",
       "      <td>20585.544083</td>\n",
       "      <td>1028.369495</td>\n",
       "      <td>1.163780e+06</td>\n",
       "      <td>9.199135</td>\n",
       "      <td>597900.477629</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.144294e+06</td>\n",
       "      <td>785176.201298</td>\n",
       "      <td>...</td>\n",
       "      <td>1.024198e+06</td>\n",
       "      <td>-855.549602</td>\n",
       "      <td>12176.073427</td>\n",
       "      <td>10.647729</td>\n",
       "      <td>10.916371</td>\n",
       "      <td>1220.065443</td>\n",
       "      <td>8.566724</td>\n",
       "      <td>1.036263e+06</td>\n",
       "      <td>85338.558539</td>\n",
       "      <td>103088.664210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>11.512994</td>\n",
       "      <td>832442.898114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1012.624877</td>\n",
       "      <td>1.028911e+06</td>\n",
       "      <td>10.906408</td>\n",
       "      <td>597900.458612</td>\n",
       "      <td>8127.016078</td>\n",
       "      <td>1.099166e+06</td>\n",
       "      <td>785176.258299</td>\n",
       "      <td>...</td>\n",
       "      <td>1.086806e+06</td>\n",
       "      <td>-787.397942</td>\n",
       "      <td>10493.095660</td>\n",
       "      <td>10.586492</td>\n",
       "      <td>9.463962</td>\n",
       "      <td>917.094909</td>\n",
       "      <td>10.231822</td>\n",
       "      <td>1.007163e+06</td>\n",
       "      <td>95695.020645</td>\n",
       "      <td>105161.109422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>11.052185</td>\n",
       "      <td>832442.896307</td>\n",
       "      <td>20585.512844</td>\n",
       "      <td>1003.953827</td>\n",
       "      <td>9.231756e+05</td>\n",
       "      <td>9.212979</td>\n",
       "      <td>597900.426764</td>\n",
       "      <td>10738.092422</td>\n",
       "      <td>1.027863e+06</td>\n",
       "      <td>785176.223468</td>\n",
       "      <td>...</td>\n",
       "      <td>1.018533e+06</td>\n",
       "      <td>-906.997242</td>\n",
       "      <td>10959.516944</td>\n",
       "      <td>10.769287</td>\n",
       "      <td>10.342160</td>\n",
       "      <td>637.027802</td>\n",
       "      <td>10.705461</td>\n",
       "      <td>1.019955e+06</td>\n",
       "      <td>80253.299882</td>\n",
       "      <td>104177.051666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11.642076</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1004.672084</td>\n",
       "      <td>9.459461e+05</td>\n",
       "      <td>9.553420</td>\n",
       "      <td>597900.450367</td>\n",
       "      <td>13524.096973</td>\n",
       "      <td>1.168144e+06</td>\n",
       "      <td>785176.254867</td>\n",
       "      <td>...</td>\n",
       "      <td>1.047017e+06</td>\n",
       "      <td>-1011.742516</td>\n",
       "      <td>16845.309819</td>\n",
       "      <td>10.483830</td>\n",
       "      <td>10.594941</td>\n",
       "      <td>1114.069590</td>\n",
       "      <td>10.321063</td>\n",
       "      <td>1.085442e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102746.516920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>10.407121</td>\n",
       "      <td>832442.831424</td>\n",
       "      <td>20585.557007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.957182e+05</td>\n",
       "      <td>8.419164</td>\n",
       "      <td>597900.423639</td>\n",
       "      <td>12894.065081</td>\n",
       "      <td>1.063199e+06</td>\n",
       "      <td>785176.190880</td>\n",
       "      <td>...</td>\n",
       "      <td>1.031009e+06</td>\n",
       "      <td>-1025.223865</td>\n",
       "      <td>18348.460040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1230.088215</td>\n",
       "      <td>10.250096</td>\n",
       "      <td>1.024812e+06</td>\n",
       "      <td>101815.745499</td>\n",
       "      <td>105163.749149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>9.144461</td>\n",
       "      <td>832442.882921</td>\n",
       "      <td>20585.548624</td>\n",
       "      <td>1042.982264</td>\n",
       "      <td>1.079217e+06</td>\n",
       "      <td>10.290930</td>\n",
       "      <td>597900.434742</td>\n",
       "      <td>9730.044411</td>\n",
       "      <td>9.758330e+05</td>\n",
       "      <td>785176.248738</td>\n",
       "      <td>...</td>\n",
       "      <td>1.020202e+06</td>\n",
       "      <td>-790.713766</td>\n",
       "      <td>12838.791399</td>\n",
       "      <td>10.561760</td>\n",
       "      <td>10.386269</td>\n",
       "      <td>1230.071653</td>\n",
       "      <td>11.034434</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90435.964659</td>\n",
       "      <td>109082.145240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>9.895803</td>\n",
       "      <td>832442.816841</td>\n",
       "      <td>20585.544187</td>\n",
       "      <td>1001.483820</td>\n",
       "      <td>9.935226e+05</td>\n",
       "      <td>10.276043</td>\n",
       "      <td>597900.436187</td>\n",
       "      <td>12080.006126</td>\n",
       "      <td>9.537706e+05</td>\n",
       "      <td>785176.270535</td>\n",
       "      <td>...</td>\n",
       "      <td>1.038143e+06</td>\n",
       "      <td>-927.126335</td>\n",
       "      <td>14383.974419</td>\n",
       "      <td>10.427384</td>\n",
       "      <td>10.442063</td>\n",
       "      <td>1076.013807</td>\n",
       "      <td>10.228285</td>\n",
       "      <td>1.054731e+06</td>\n",
       "      <td>100889.137964</td>\n",
       "      <td>106036.091106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows Ã— 832 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          x0             x1            x2           x3            x4  \\\n",
       "0  10.891876  832442.812375  20585.544083  1028.369495  1.163780e+06   \n",
       "1  11.512994  832442.898114           NaN  1012.624877  1.028911e+06   \n",
       "2  11.052185  832442.896307  20585.512844  1003.953827  9.231756e+05   \n",
       "3  11.642076            NaN           NaN  1004.672084  9.459461e+05   \n",
       "4  10.407121  832442.831424  20585.557007          NaN  9.957182e+05   \n",
       "5   9.144461  832442.882921  20585.548624  1042.982264  1.079217e+06   \n",
       "6   9.895803  832442.816841  20585.544187  1001.483820  9.935226e+05   \n",
       "\n",
       "          x5             x6            x7            x8             x9  ...  \\\n",
       "0   9.199135  597900.477629           NaN  1.144294e+06  785176.201298  ...   \n",
       "1  10.906408  597900.458612   8127.016078  1.099166e+06  785176.258299  ...   \n",
       "2   9.212979  597900.426764  10738.092422  1.027863e+06  785176.223468  ...   \n",
       "3   9.553420  597900.450367  13524.096973  1.168144e+06  785176.254867  ...   \n",
       "4   8.419164  597900.423639  12894.065081  1.063199e+06  785176.190880  ...   \n",
       "5  10.290930  597900.434742   9730.044411  9.758330e+05  785176.248738  ...   \n",
       "6  10.276043  597900.436187  12080.006126  9.537706e+05  785176.270535  ...   \n",
       "\n",
       "           x822         x823          x824       x825       x826         x827  \\\n",
       "0  1.024198e+06  -855.549602  12176.073427  10.647729  10.916371  1220.065443   \n",
       "1  1.086806e+06  -787.397942  10493.095660  10.586492   9.463962   917.094909   \n",
       "2  1.018533e+06  -906.997242  10959.516944  10.769287  10.342160   637.027802   \n",
       "3  1.047017e+06 -1011.742516  16845.309819  10.483830  10.594941  1114.069590   \n",
       "4  1.031009e+06 -1025.223865  18348.460040        NaN        NaN  1230.088215   \n",
       "5  1.020202e+06  -790.713766  12838.791399  10.561760  10.386269  1230.071653   \n",
       "6  1.038143e+06  -927.126335  14383.974419  10.427384  10.442063  1076.013807   \n",
       "\n",
       "        x828          x829           x830           x831  \n",
       "0   8.566724  1.036263e+06   85338.558539  103088.664210  \n",
       "1  10.231822  1.007163e+06   95695.020645  105161.109422  \n",
       "2  10.705461  1.019955e+06   80253.299882  104177.051666  \n",
       "3  10.321063  1.085442e+06            NaN  102746.516920  \n",
       "4  10.250096  1.024812e+06  101815.745499  105163.749149  \n",
       "5  11.034434           NaN   90435.964659  109082.145240  \n",
       "6  10.228285  1.054731e+06  100889.137964  106036.091106  \n",
       "\n",
       "[7 rows x 832 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = pd.read_csv(\"X_train.csv\")\n",
    "y_train = pd.read_csv(\"Y_train.csv\")\n",
    "x_test = pd.read_csv(\"X_test.csv\")\n",
    "# remove the id colum of x_train and x_test\n",
    "x_train = x_train.iloc[:, 1:]\n",
    "x_test = x_test.iloc[:, 1:]\n",
    "# remove the id column of y_train\n",
    "# can also use drop() funcation\n",
    "y_train = y_train.iloc[:,1:]\n",
    "\n",
    "# check whether read data correctly\n",
    "# print(x_train.shape)\n",
    "x_train.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Filling the missing values\n",
    "After reading data, we could see there are many missing values('NAN') in the dataset. So before we do further processing, we should choose proper methods to fill the missing values.    \n",
    "\n",
    "Mean value of each column or Median value of each column can be used to do the fulfillment. But here we will take KNN methods to get more accurate outcome.  \n",
    "  \n",
    "  Use *KNNImputer* from *sklearn.impute* to fill the missing values('NAN')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = KNNImputer( n_neighbors=10, weights='uniform', metric='nan_euclidean')\n",
    "\n",
    "x_train = imputer.fit_transform(x_train)\n",
    "x_train = pd.DataFrame(x_train)\n",
    "x_test = imputer.fit_transform(x_test)\n",
    "x_test = pd.DataFrame(x_test)\n",
    "\n",
    "# x_train = xtrain.fillna(x_train.mean())\n",
    "# x_test = xtest.fillna(x_train.mean())\n",
    "# x_train = xtrain.fillna(x_train.median())\n",
    "# x_test = xtest.fillna(x_train.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Scaling the data\n",
    "Each column's data varies a lot. To take all data as same weight(since we do not know which colums are useful yet), we should scale the data: mapping each column value to a small range.  \n",
    "  \n",
    "  Use MinMaxScaler and StandardScaler from sklearn.preprocessing to do this. We choose to use StandardScaler in our code by trying both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>822</th>\n",
       "      <th>823</th>\n",
       "      <th>824</th>\n",
       "      <th>825</th>\n",
       "      <th>826</th>\n",
       "      <th>827</th>\n",
       "      <th>828</th>\n",
       "      <th>829</th>\n",
       "      <th>830</th>\n",
       "      <th>831</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.942493</td>\n",
       "      <td>-1.700031</td>\n",
       "      <td>0.677888</td>\n",
       "      <td>-0.776661</td>\n",
       "      <td>1.763823</td>\n",
       "      <td>-0.923420</td>\n",
       "      <td>1.750336</td>\n",
       "      <td>-0.359669</td>\n",
       "      <td>1.477087</td>\n",
       "      <td>-0.900275</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.926136</td>\n",
       "      <td>0.138346</td>\n",
       "      <td>-0.555133</td>\n",
       "      <td>0.357323</td>\n",
       "      <td>0.936976</td>\n",
       "      <td>0.673121</td>\n",
       "      <td>-1.477605</td>\n",
       "      <td>-0.516184</td>\n",
       "      <td>-1.576968</td>\n",
       "      <td>-0.702403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.608230</td>\n",
       "      <td>1.448678</td>\n",
       "      <td>0.039286</td>\n",
       "      <td>-1.353328</td>\n",
       "      <td>0.327574</td>\n",
       "      <td>0.896183</td>\n",
       "      <td>1.046030</td>\n",
       "      <td>-1.397727</td>\n",
       "      <td>1.018262</td>\n",
       "      <td>1.147418</td>\n",
       "      <td>...</td>\n",
       "      <td>1.350061</td>\n",
       "      <td>0.567110</td>\n",
       "      <td>-1.252698</td>\n",
       "      <td>0.133718</td>\n",
       "      <td>-0.580650</td>\n",
       "      <td>-0.712429</td>\n",
       "      <td>0.221062</td>\n",
       "      <td>-1.592495</td>\n",
       "      <td>-0.457268</td>\n",
       "      <td>0.082128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.114318</td>\n",
       "      <td>1.382298</td>\n",
       "      <td>-0.440160</td>\n",
       "      <td>-1.670916</td>\n",
       "      <td>-0.798419</td>\n",
       "      <td>-0.908666</td>\n",
       "      <td>-0.133529</td>\n",
       "      <td>0.223024</td>\n",
       "      <td>0.293307</td>\n",
       "      <td>-0.103843</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.132115</td>\n",
       "      <td>-0.185328</td>\n",
       "      <td>-1.059374</td>\n",
       "      <td>0.801187</td>\n",
       "      <td>0.336981</td>\n",
       "      <td>-1.993236</td>\n",
       "      <td>0.704249</td>\n",
       "      <td>-1.119355</td>\n",
       "      <td>-2.126766</td>\n",
       "      <td>-0.290390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.746586</td>\n",
       "      <td>-0.178166</td>\n",
       "      <td>0.320567</td>\n",
       "      <td>-1.644609</td>\n",
       "      <td>-0.555932</td>\n",
       "      <td>-0.545825</td>\n",
       "      <td>0.740655</td>\n",
       "      <td>1.952357</td>\n",
       "      <td>1.719573</td>\n",
       "      <td>1.024132</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096514</td>\n",
       "      <td>-0.844314</td>\n",
       "      <td>1.380182</td>\n",
       "      <td>-0.241149</td>\n",
       "      <td>0.601113</td>\n",
       "      <td>0.188379</td>\n",
       "      <td>0.312102</td>\n",
       "      <td>1.302758</td>\n",
       "      <td>0.221515</td>\n",
       "      <td>-0.831924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.422913</td>\n",
       "      <td>-1.000453</td>\n",
       "      <td>1.140450</td>\n",
       "      <td>0.039348</td>\n",
       "      <td>-0.025899</td>\n",
       "      <td>-1.754709</td>\n",
       "      <td>-0.249274</td>\n",
       "      <td>1.561282</td>\n",
       "      <td>0.652576</td>\n",
       "      <td>-1.274522</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.678502</td>\n",
       "      <td>-0.929129</td>\n",
       "      <td>2.003211</td>\n",
       "      <td>-0.412350</td>\n",
       "      <td>-0.481637</td>\n",
       "      <td>0.718957</td>\n",
       "      <td>0.239704</td>\n",
       "      <td>-0.939721</td>\n",
       "      <td>0.204480</td>\n",
       "      <td>0.083127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>-0.930454</td>\n",
       "      <td>0.890729</td>\n",
       "      <td>0.840420</td>\n",
       "      <td>-0.241450</td>\n",
       "      <td>0.863298</td>\n",
       "      <td>0.240210</td>\n",
       "      <td>0.161940</td>\n",
       "      <td>-0.402693</td>\n",
       "      <td>-0.235687</td>\n",
       "      <td>0.803951</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.071423</td>\n",
       "      <td>0.546249</td>\n",
       "      <td>-0.280449</td>\n",
       "      <td>0.043411</td>\n",
       "      <td>0.383071</td>\n",
       "      <td>0.718881</td>\n",
       "      <td>1.039854</td>\n",
       "      <td>-0.043952</td>\n",
       "      <td>-1.025857</td>\n",
       "      <td>1.566448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>-0.125137</td>\n",
       "      <td>-1.536023</td>\n",
       "      <td>0.681600</td>\n",
       "      <td>-1.761383</td>\n",
       "      <td>-0.049280</td>\n",
       "      <td>0.224343</td>\n",
       "      <td>0.215460</td>\n",
       "      <td>1.055979</td>\n",
       "      <td>-0.459999</td>\n",
       "      <td>1.586990</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.419166</td>\n",
       "      <td>-0.311966</td>\n",
       "      <td>0.360002</td>\n",
       "      <td>-0.447258</td>\n",
       "      <td>0.441370</td>\n",
       "      <td>0.014342</td>\n",
       "      <td>0.217453</td>\n",
       "      <td>0.166864</td>\n",
       "      <td>0.104299</td>\n",
       "      <td>0.413355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows Ã— 832 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.942493 -1.700031  0.677888 -0.776661  1.763823 -0.923420  1.750336   \n",
       "1  1.608230  1.448678  0.039286 -1.353328  0.327574  0.896183  1.046030   \n",
       "2  1.114318  1.382298 -0.440160 -1.670916 -0.798419 -0.908666 -0.133529   \n",
       "3  1.746586 -0.178166  0.320567 -1.644609 -0.555932 -0.545825  0.740655   \n",
       "4  0.422913 -1.000453  1.140450  0.039348 -0.025899 -1.754709 -0.249274   \n",
       "5 -0.930454  0.890729  0.840420 -0.241450  0.863298  0.240210  0.161940   \n",
       "6 -0.125137 -1.536023  0.681600 -1.761383 -0.049280  0.224343  0.215460   \n",
       "\n",
       "        7         8         9    ...       822       823       824       825  \\\n",
       "0 -0.359669  1.477087 -0.900275  ... -0.926136  0.138346 -0.555133  0.357323   \n",
       "1 -1.397727  1.018262  1.147418  ...  1.350061  0.567110 -1.252698  0.133718   \n",
       "2  0.223024  0.293307 -0.103843  ... -1.132115 -0.185328 -1.059374  0.801187   \n",
       "3  1.952357  1.719573  1.024132  ... -0.096514 -0.844314  1.380182 -0.241149   \n",
       "4  1.561282  0.652576 -1.274522  ... -0.678502 -0.929129  2.003211 -0.412350   \n",
       "5 -0.402693 -0.235687  0.803951  ... -1.071423  0.546249 -0.280449  0.043411   \n",
       "6  1.055979 -0.459999  1.586990  ... -0.419166 -0.311966  0.360002 -0.447258   \n",
       "\n",
       "        826       827       828       829       830       831  \n",
       "0  0.936976  0.673121 -1.477605 -0.516184 -1.576968 -0.702403  \n",
       "1 -0.580650 -0.712429  0.221062 -1.592495 -0.457268  0.082128  \n",
       "2  0.336981 -1.993236  0.704249 -1.119355 -2.126766 -0.290390  \n",
       "3  0.601113  0.188379  0.312102  1.302758  0.221515 -0.831924  \n",
       "4 -0.481637  0.718957  0.239704 -0.939721  0.204480  0.083127  \n",
       "5  0.383071  0.718881  1.039854 -0.043952 -1.025857  1.566448  \n",
       "6  0.441370  0.014342  0.217453  0.166864  0.104299  0.413355  \n",
       "\n",
       "[7 rows x 832 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select scaling method\n",
    "scaler = preprocessing.StandardScaler()\n",
    "# scaler = preprocessing.MinMaxScaler(feature_range = (0,1))\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_train = pd.DataFrame(x_train_scaled, columns = x_train.columns)\n",
    "x_test_scaled = scaler.fit_transform(x_test)\n",
    "x_test = pd.DataFrame(x_test_scaled, columns = x_test.columns)\n",
    "\n",
    "# check the data's correctness\n",
    "x_train.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Selection\n",
    "  \n",
    "  There are 832 features(columns) of each data. Among them exists useless or redundant features.Too many features may cause problems such as low-effiency or overfit. It's necessary to reduce features' number.   \n",
    "  Here are several methods to select features:\n",
    "  - Filter\n",
    "  - Wrapper\n",
    "  - Embedded \n",
    "  \n",
    "<br>We first tried SelectKBest method from sklearn but it doesn't work (cannot distinguish which are useful features because it may choose relevant features and cause overfit). So in our code we finally choose Lasso to pick up features.\n",
    "<br><br>Lasso methods fit such problems: small sample but relatively many features. L1 regularization adds the L1 norm of the coefficient W to the loss function as a penalty term. Since the regular term is non-zero, this forces the coefficients corresponding to weak features to be zero. Thus L1 regularization tends to make the learned model sparse (the coefficient W is often 0). That will meet our requirements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>35</th>\n",
       "      <th>85</th>\n",
       "      <th>129</th>\n",
       "      <th>131</th>\n",
       "      <th>155</th>\n",
       "      <th>184</th>\n",
       "      <th>187</th>\n",
       "      <th>214</th>\n",
       "      <th>227</th>\n",
       "      <th>302</th>\n",
       "      <th>...</th>\n",
       "      <th>575</th>\n",
       "      <th>579</th>\n",
       "      <th>668</th>\n",
       "      <th>685</th>\n",
       "      <th>687</th>\n",
       "      <th>726</th>\n",
       "      <th>761</th>\n",
       "      <th>779</th>\n",
       "      <th>785</th>\n",
       "      <th>789</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.764399</td>\n",
       "      <td>-0.387242</td>\n",
       "      <td>0.128673</td>\n",
       "      <td>-1.352998</td>\n",
       "      <td>1.556735</td>\n",
       "      <td>-0.011368</td>\n",
       "      <td>0.180149</td>\n",
       "      <td>0.836654</td>\n",
       "      <td>-1.609875</td>\n",
       "      <td>-0.640106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.616306</td>\n",
       "      <td>-1.539756</td>\n",
       "      <td>1.590178</td>\n",
       "      <td>0.000903</td>\n",
       "      <td>-1.076245</td>\n",
       "      <td>-0.584159</td>\n",
       "      <td>-0.270960</td>\n",
       "      <td>1.778407</td>\n",
       "      <td>1.427256</td>\n",
       "      <td>-0.709121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.227643</td>\n",
       "      <td>1.930197</td>\n",
       "      <td>-0.078653</td>\n",
       "      <td>0.203304</td>\n",
       "      <td>-3.323633</td>\n",
       "      <td>-1.555959</td>\n",
       "      <td>-1.036320</td>\n",
       "      <td>-0.357919</td>\n",
       "      <td>0.488278</td>\n",
       "      <td>0.642164</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029395</td>\n",
       "      <td>1.993414</td>\n",
       "      <td>1.521426</td>\n",
       "      <td>-2.408154</td>\n",
       "      <td>-1.248679</td>\n",
       "      <td>0.581506</td>\n",
       "      <td>1.976307</td>\n",
       "      <td>0.170829</td>\n",
       "      <td>1.189660</td>\n",
       "      <td>-1.406099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.827556</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>0.161924</td>\n",
       "      <td>1.012361</td>\n",
       "      <td>1.042360</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.138262</td>\n",
       "      <td>-0.653667</td>\n",
       "      <td>-0.360630</td>\n",
       "      <td>-0.601899</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.307966</td>\n",
       "      <td>-1.664253</td>\n",
       "      <td>0.809962</td>\n",
       "      <td>-0.178326</td>\n",
       "      <td>1.532533</td>\n",
       "      <td>-0.488529</td>\n",
       "      <td>0.193061</td>\n",
       "      <td>-1.228298</td>\n",
       "      <td>-0.020423</td>\n",
       "      <td>1.200787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.986452</td>\n",
       "      <td>-0.674918</td>\n",
       "      <td>-0.172366</td>\n",
       "      <td>1.725593</td>\n",
       "      <td>3.296079</td>\n",
       "      <td>2.148550</td>\n",
       "      <td>0.203023</td>\n",
       "      <td>-0.692671</td>\n",
       "      <td>2.014332</td>\n",
       "      <td>-0.758568</td>\n",
       "      <td>...</td>\n",
       "      <td>1.206968</td>\n",
       "      <td>0.918562</td>\n",
       "      <td>-1.233334</td>\n",
       "      <td>2.080282</td>\n",
       "      <td>0.281289</td>\n",
       "      <td>5.266438</td>\n",
       "      <td>1.033473</td>\n",
       "      <td>2.903278</td>\n",
       "      <td>-0.884301</td>\n",
       "      <td>0.678749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.738774</td>\n",
       "      <td>-0.580780</td>\n",
       "      <td>0.343361</td>\n",
       "      <td>-0.288739</td>\n",
       "      <td>0.197806</td>\n",
       "      <td>0.736512</td>\n",
       "      <td>1.736880</td>\n",
       "      <td>0.856669</td>\n",
       "      <td>-0.070456</td>\n",
       "      <td>0.103454</td>\n",
       "      <td>...</td>\n",
       "      <td>2.104688</td>\n",
       "      <td>-0.560072</td>\n",
       "      <td>1.743183</td>\n",
       "      <td>0.984172</td>\n",
       "      <td>-0.823479</td>\n",
       "      <td>0.578459</td>\n",
       "      <td>0.374598</td>\n",
       "      <td>0.207123</td>\n",
       "      <td>0.509101</td>\n",
       "      <td>0.553017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        35        85        129       131       155       184       187  \\\n",
       "0  0.764399 -0.387242  0.128673 -1.352998  1.556735 -0.011368  0.180149   \n",
       "1 -0.227643  1.930197 -0.078653  0.203304 -3.323633 -1.555959 -1.036320   \n",
       "2 -0.827556 -0.473649  0.161924  1.012361  1.042360  0.032609  0.138262   \n",
       "3  0.986452 -0.674918 -0.172366  1.725593  3.296079  2.148550  0.203023   \n",
       "4  0.738774 -0.580780  0.343361 -0.288739  0.197806  0.736512  1.736880   \n",
       "\n",
       "        214       227       302  ...       575       579       668       685  \\\n",
       "0  0.836654 -1.609875 -0.640106  ...  0.616306 -1.539756  1.590178  0.000903   \n",
       "1 -0.357919  0.488278  0.642164  ... -0.029395  1.993414  1.521426 -2.408154   \n",
       "2 -0.653667 -0.360630 -0.601899  ... -0.307966 -1.664253  0.809962 -0.178326   \n",
       "3 -0.692671  2.014332 -0.758568  ...  1.206968  0.918562 -1.233334  2.080282   \n",
       "4  0.856669 -0.070456  0.103454  ...  2.104688 -0.560072  1.743183  0.984172   \n",
       "\n",
       "        687       726       761       779       785       789  \n",
       "0 -1.076245 -0.584159 -0.270960  1.778407  1.427256 -0.709121  \n",
       "1 -1.248679  0.581506  1.976307  0.170829  1.189660 -1.406099  \n",
       "2  1.532533 -0.488529  0.193061 -1.228298 -0.020423  1.200787  \n",
       "3  0.281289  5.266438  1.033473  2.903278 -0.884301  0.678749  \n",
       "4 -0.823479  0.578459  0.374598  0.207123  0.509101  0.553017  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alpha: the weight of L1 penalty term\n",
    "coefficients_train = Lasso(alpha = 0.5)\n",
    "coefficients_train.fit(x_train, y_train)\n",
    "\n",
    "choose_features = (coefficients_train.coef_ != 0)\n",
    "# print(coefficient_train.coef_)\n",
    "\n",
    "x_train = x_train.loc[:, choose_features]\n",
    "x_test = x_test.loc[:, choose_features]\n",
    "\n",
    "#check choose how many features\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.Outlier detection\n",
    "<br>Use IsolationForest from sklearn to do isolation forest methods. Detect and remove outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create IsolationForest class\n",
    "isofore = IsolationForest(n_estimators = 600,max_features = 29, contamination = 0.015)\n",
    "\n",
    "\"\"\"\n",
    "IsolationForest(*, n_estimators=100, max_samples='auto', contamination='auto', max_features=1.0, bootstrap=False, n_jobs=None, random_state=None, verbose=0, warm_start=False)\n",
    "\"\"\"\n",
    "x_train_isoforest = isofore.fit_predict(x_train)\n",
    "\n",
    "# Remove outliers\n",
    "x_train = x_train[(x_train_isoforest != -1)]\n",
    "y_train = y_train[(x_train_isoforest != -1)]\n",
    "\n",
    "# print(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n",
    "<br> Use processed data to train and predict the 'X_test.csv'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of R2 scores: 0.5271123378999729\n",
      "Standard deviation of R2 scores: 0.04866950493930913\n"
     ]
    }
   ],
   "source": [
    "# Step 5 - Model Fit: XGBoost\n",
    "\n",
    "regression = xgb.XGBRegressor(objective=\"reg:squarederror\", random_state=48)\n",
    "\n",
    "# Use 5-fold Cross Validation to See the performance and tune the parameter\n",
    "\n",
    "cv_means = []\n",
    "cv_stds = []\n",
    "for i in np.arange(10):\n",
    "    scores = cross_val_score(estimator = regression,\n",
    "                                 X = x_train,\n",
    "                                 y = y_train,\n",
    "                                 scoring = 'r2',\n",
    "                                 cv = KFold(n_splits=5, shuffle = True))\n",
    "    cv_means.append(np.mean(scores))\n",
    "    cv_stds.append(np.std(scores))\n",
    "\n",
    "print(\"Average of R2 scores:\", np.mean(cv_means))\n",
    "print(\"Standard deviation of R2 scores:\", np.mean(cv_stds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction and Write into csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = xgb.XGBRegressor(objective = \"reg:squarederror\", random_state = 48)\n",
    "regression.fit(x_train, y_train)\n",
    "\n",
    "y_pred = regression.predict(x_test)\n",
    "\n",
    "#print(y_pred)\n",
    "prediction_results = pd.DataFrame(data = y_pred,columns = ['y'])\n",
    "# Using DataFrame.insert() to add a column\n",
    "index = [i for i in range(len(prediction_results))]\n",
    "prediction_results.insert(0,\"id\",index)\n",
    "  \n",
    "# Observe the result\n",
    "prediction_results\n",
    "prediction_results.to_csv('result_xgb.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
