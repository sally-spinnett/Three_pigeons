# -*- coding: utf-8 -*-
"""amltask1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dHFf-7BuXB1t1VQrjrKwcXbAcxqc0vm_
"""

from google.colab import drive
drive.mount('/content/gdrive')

cd /content/gdrive/MyDrive/ETH/AML/task1

import numpy as np
import pandas as pd

train_cvsx=pd.read_csv('X_train.csv',dtype=np.double)
train_x=train_cvsx.iloc[:,1:]

train_cvsx.iloc[0:3]

train_x.iloc[0:3]

train_cvsy=pd.read_csv('y_train.csv',dtype=np.double)
train_y=train_cvsy.iloc[:,1:]

train_y.iloc[0:3]

"""###preprocess
  #1.imputation of missing values
  ###scikit-learn KNN imputer
  #potential problem : sensitive to outlier
  # parameter adjust n_neighbors= xxx try  different # could 
"""

from sklearn.impute import KNNImputer

imputer = KNNImputer(n_neighbors=5, weights='uniform', metric='nan_euclidean')
train_xp=imputer.fit_transform(train_x)

train_xp=pd.DataFrame(train_xp)

#df.isnull().sum()

"""#Outlier Detection
## isolation forest
 max_features, contamination, could try to reset 

youâ€™ll generate the biggest performance boost by using a grid search technique with cross validation #todo
"""

from sklearn.ensemble import IsolationForest

isofore=IsolationForest(n_estimators=50,max_features=10,max_samples='auto')
train_xppl=isofore.fit_predict(train_xp)
train_xpp=train_xp[(train_xppl!=-1)]
train_ypp=train_y[(train_xppl!=-1)]

train_ypp.shape

train_xpp.shape

train_y.shape

"""simluate train test split


"""

xtrain=train_xpp.iloc[:700,:]
ytrain=train_ypp.iloc[:700,:]
xtest=train_xpp.iloc[700:1000,:]
ytest=train_ypp.iloc[700:1000,:]

"""#Feature selection 
As F-test captures only linear dependency, it rates x_1 as the most discriminative feature. On the other hand, mutual information can capture any kind of dependency between variables and it rates x_2 as the most discriminative feature, which probably agrees better with our intuitive perception for this example. Both methods correctly marks x_3 as irrelevant.

"""

from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import mutual_info_regression

selector = SelectKBest(score_func=mutual_info_regression, k=100)
selector.fit(xtrain,np.ravel(ytrain))
train_xppp=selector.transform(xtrain)
test_xp1p3=selector.transform(xtest)

test_xp1p3.shape

""" To identify the selected features we use get_support() function and filter out them from the features name list."""

filter = selector.get_support()

"""Regression

"""

from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF,DotProduct, ConstantKernel,WhiteKernel,Matern,RationalQuadratic

## simulate test & train





kernel=RBF()+WhiteKernel()
gpr=gpr = GaussianProcessRegressor(kernel=kernel,alpha=1e-10, n_restarts_optimizer=2, normalize_y=True, copy_X_train=False, random_state=None)
#gpr.fit(train_xppp, ytrain)
gpr.fit(xtrain,ytrain)
#ypred=gpr.predict(test_xp1p3)
ypred=gpr.predict(xtest)



"""evaluation"""

from sklearn.metrics import r2_score

score=r2_score(ytest,ypred)
print(score)

### test
from sklearn import model_selection
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import cross_val_score
from sklearn.metrics import mean_squared_error

X_train, X_test, y_train, y_test = train_test_split(train_xp, train_y, test_size=0.3, random_state=1)
# scale the data using StandardScaler() so the various column values are on an even scale.
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

#X_train.shape

"""grid search tuning hyperparameter"""

model = IsolationForest(random_state=47)

param_grid = {'n_estimators': [1000, 1500], 
              'max_samples': [10], 
              'contamination': ['auto', 0.0001, 0.0002], 
              'max_features': [10, 15], 
              'bootstrap': [True], 
              'n_jobs': [-1]}

grid_search = model_selection.GridSearchCV(model, 
                                           param_grid,
                                           scoring="neg_mean_squared_error", 
                                           refit=True,
                                           cv=10, 
                                           return_train_score=True)
grid_search.fit(X_train, y_train)

best_model = grid_search.fit(X_train, y_train)
print('Optimum parameters', best_model.best_params_)