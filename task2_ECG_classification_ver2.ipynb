{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20f5fb31",
   "metadata": {},
   "source": [
    "# 0. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25de43e",
   "metadata": {},
   "source": [
    "While the previous projects dealt with medical image features, we turn now to the classification of entire time series into one of 4 classes. This time you will work with the original ECG recordings of different length sampled as 300Hz to predict heart rhythm.\n",
    "\n",
    "X_train.csv: the training signals, each row is one sample indexed by an id, the first column contains the id, and the rest columns are up to 17842 sample points.\n",
    "\n",
    "X_test.csv: the test set, same structure\n",
    "\n",
    "y_train.csv: the training targets (signal classes)\n",
    "\n",
    "The problem was a classification task. We had ECG measurements of 4 classes that were unbalanced and of not the same length. We used different techinques to extract features that we used for the classification. For each ECG signal we extracted the autocorrelation, the average and the power. We also extracted 15 coefficients of the FFT. For each ECG using biosspy we extracted the heartbeats, averaged them and created a characteristic average of the same length of each patient. For each of these signals (after normalization) we extracted the energy of the wave, the T, S, P, R, Q peaks, the ST QRS PR intervals, QRS/T and QRS/P ratios, the median, mean and interval of the amplitude and the db2 coefficients. Finally, the library biosspy gave us the locations of peaks in the original wave, the timings as well as the heart beats and their timings. For all of them we calculated the mean, median and standard deviation. We also extracted the mean, median and standard deviation of the differences between the peaks' timings( important feature to classify noise, normal heart rate and abnormal heart rhythms). Using all of these features we trained a GradientBoosting model which was fine-tuned using a Cross-validation grid search. The model has 0.817 mean score in the cross-validation and 0.833 in the public scoreboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "efc13beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import csv\n",
    "import os\n",
    "\n",
    "import biosppy as biosppy\n",
    "import biosppy.signals.ecg as ecg\n",
    "import pywt\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy import stats\n",
    "from statistics import pstdev,variance\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d8d57f",
   "metadata": {},
   "source": [
    "# 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bd3871",
   "metadata": {},
   "source": [
    "## 1.0 Read data from CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de499ab1",
   "metadata": {},
   "source": [
    "Use pandas to read csv file. Then discard unnecessary columns (id column). Check the correctness of data reading in the end of the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60b8b01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x17832</th>\n",
       "      <th>x17833</th>\n",
       "      <th>x17834</th>\n",
       "      <th>x17835</th>\n",
       "      <th>x17836</th>\n",
       "      <th>x17837</th>\n",
       "      <th>x17838</th>\n",
       "      <th>x17839</th>\n",
       "      <th>x17840</th>\n",
       "      <th>x17841</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-64</td>\n",
       "      <td>-66</td>\n",
       "      <td>-69</td>\n",
       "      <td>-72</td>\n",
       "      <td>-75</td>\n",
       "      <td>-77</td>\n",
       "      <td>-80</td>\n",
       "      <td>-86</td>\n",
       "      <td>-89</td>\n",
       "      <td>-83</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>505</td>\n",
       "      <td>500</td>\n",
       "      <td>496</td>\n",
       "      <td>492</td>\n",
       "      <td>487</td>\n",
       "      <td>480</td>\n",
       "      <td>475</td>\n",
       "      <td>476</td>\n",
       "      <td>483</td>\n",
       "      <td>495</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-21</td>\n",
       "      <td>-16</td>\n",
       "      <td>-12</td>\n",
       "      <td>-7</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 17842 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    x0   x1   x2   x3   x4   x5   x6   x7   x8   x9  ...  x17832  x17833  \\\n",
       "0  -64  -66  -69  -72  -75  -77  -80  -86  -89  -83  ...     NaN     NaN   \n",
       "1  505  500  496  492  487  480  475  476  483  495  ...     NaN     NaN   \n",
       "2  -21  -16  -12   -7   -3    0    1    2    4    5  ...     NaN     NaN   \n",
       "\n",
       "   x17834  x17835  x17836  x17837  x17838  x17839  x17840  x17841  \n",
       "0     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
       "1     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
       "2     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
       "\n",
       "[3 rows x 17842 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = pd.read_csv(\"task2/X_train.csv\")\n",
    "y_train = pd.read_csv(\"task2/y_train.csv\")\n",
    "x_test = pd.read_csv(\"task2/X_test.csv\")\n",
    "\n",
    "x_train.pop(\"id\")\n",
    "y_train.pop(\"id\")\n",
    "x_test.pop(\"id\")\n",
    "\n",
    "x_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7931ec2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5117, 17842) (3411, 17842) (5117, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3397e92b",
   "metadata": {},
   "source": [
    "## 1.1 Extract frequency domain features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "704319e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract frequency domain features: FFT, power, average and autocorrelation\n",
    "# before padding to 9000 points\n",
    "autocorr = []\n",
    "ptp = []\n",
    "avg = []\n",
    "fft = []\n",
    "\n",
    "for i in range(len(x_train)):\n",
    "    # extract i-th single row as a dataframe and drop na values\n",
    "    signal = x_train.loc[i].dropna().to_numpy(dtype='float32')\n",
    "    signal_series = pd.Series(signal)\n",
    "    # extract autocorrelation, average, ptp(max-min)\n",
    "    autocorr.append(signal_series.autocorr(lag=2))\n",
    "    avg.append(np.average(signal))\n",
    "    ptp.append(np.ptp(signal))\n",
    "    f_coefficients = np.fft.fft(signal)\n",
    "    f_coefficients = f_coefficients[0:800]\n",
    "    n = 15\n",
    "    f = f_coefficients.argsort()[-n:][::-1]\n",
    "    fft.append(f)\n",
    "     \n",
    "autocorr = np.transpose(np.array([autocorr]))\n",
    "ptp = np.transpose(np.array([ptp]))\n",
    "avg = np.transpose(np.array([avg]))\n",
    "fft = np.array(fft)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cecd2d",
   "metadata": {},
   "source": [
    "## 1.2 Time Series Analysis using Biosppy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4274a517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for extracting average of squared rpeaks differences\n",
    "def mean_sqrd_diff(rpeaks):\n",
    "    diff = np.diff(rpeaks)\n",
    "    mean_sqrd = np.mean(diff*diff)\n",
    "    return mean_sqrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6971966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process a raw ECG signal and extract relevant signal features using default parameters\n",
    "# return ts, filtered, rpeaks, templates_ts, heartbeat templates\n",
    "# and heart_rate_ts, heart_rate\n",
    "ts_list = []\n",
    "filtered_list = []\n",
    "rpeaks_list = []\n",
    "templates_ts_list = []\n",
    "templates_list = []\n",
    "heart_rate_ts_list = []\n",
    "heart_rate_list = []\n",
    "\n",
    "for i in range(len(x_train)):\n",
    "# print(i)\n",
    "    ts, filtered, rpeaks, templates_ts, templates, heart_rate_ts, heart_rate = \\\n",
    "        biosppy.signals.ecg.ecg(signal = x_train.loc[i].dropna().to_numpy(dtype='float32'),\n",
    "                                sampling_rate=300.0, show=False)\n",
    "\n",
    "# # Correct R-peak locations to the maximum, introduce some tolerance level\n",
    "#     rpeaks = ecg.correct_rpeaks(signal = x_train.loc[i].dropna().to_numpy(dtype='float32'),\n",
    "#                                 rpeaks = rpeaks, sampling_rate = 300.0,\n",
    "#                                 tol = 0.01)  \n",
    "# # Set heart rates to array of nans if contains no elements, otherwise min and max are not defined\n",
    "#     if len(heart_rate) == 0:\n",
    "#         heart_rate = np.array([np.nan, np.nan])\n",
    "#     if len(heart_rate_ts) == 0:\n",
    "#         heart_rate_ts = np.array([np.nan, np.nan])\n",
    "        \n",
    "    filtered_list.append(filtered)\n",
    "    rpeaks_list.append(rpeaks)\n",
    "    templates_ts_list.append(templates_ts)\n",
    "    templates_list.append(templates)\n",
    "    heart_rate_ts_list.append(heart_rate_ts)\n",
    "    heart_rate_list.append(heart_rate)\n",
    "    ts_list.append(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f32cb482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find the average characteristic heartbeat and try to plot one sample\n",
    "normalized_templates = []\n",
    "average_heartbeats = []\n",
    "for i in range(len(templates_list)):\n",
    "    normalized_templates.append(normalize(templates_list[i]))\n",
    "    average_heartbeats.append(sum(normalized_templates[i])/len(normalized_templates[i]))\n",
    "    \n",
    "plt.plot(average_heartbeats[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb501609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find P,Q,R,S,T\n",
    "P_list = []\n",
    "Q_list = []\n",
    "R_list = []\n",
    "S_list = []\n",
    "T_list = []\n",
    "\n",
    "P_value_list = []\n",
    "Q_value_list = []\n",
    "S_value_list = []\n",
    "T_value_list = []\n",
    "\n",
    "def find_points(i):\n",
    "    current = average_heartbeats[i]\n",
    "    # Find R(the peak)\n",
    "    sample_point = np.where(current == max(current))\n",
    "    R = sample_point[0]\n",
    "    \n",
    "    first_half = current[0:R[0]]\n",
    "    sample_point = np.where(current == min(first_half[R[0]-30:R[0]]))\n",
    "    Q = sample_point[0]\n",
    "    \n",
    "    sample_point = np.where(first_half[0:Q[0]] == max(first_half[0:Q[0]]))\n",
    "    P = sample_point[0]\n",
    "    \n",
    "    second_half = current[R[0]+1:]\n",
    "    sample_point = np.where(current == min(second_half[0:30]))\n",
    "    S = sample_point[0]\n",
    "    \n",
    "    sample_point = np.where(current == max(second_half[(S[0]-R[0]+1):]))\n",
    "    T = sample_point[0]\n",
    "    \n",
    "    return P,Q,R,S,T\n",
    "\n",
    "# current = average_heartbeats[256]\n",
    "# plt.plot(current)\n",
    "# plt.scatter(find_points(256)[0],current[find_points(256)[0]],label='P')\n",
    "# plt.scatter(find_points(256)[1],current[find_points(256)[1]],label='Q')\n",
    "# plt.scatter(find_points(256)[2],current[find_points(256)[2]],label='R')\n",
    "# plt.scatter(find_points(256)[3],current[find_points(256)[3]],label='S')\n",
    "# plt.scatter(find_points(256)[4],current[find_points(256)[4]],label='T')\n",
    "# plt.plot(np.arange(0, 180),np.zeros(180), 'r--') \n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "530737ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(average_heartbeats)):\n",
    "#     print(i)\n",
    "    P_list.append(find_points(i)[0])\n",
    "    Q_list.append(find_points(i)[1])\n",
    "    R_list.append(find_points(i)[2])\n",
    "    S_list.append(find_points(i)[3])\n",
    "    T_list.append(find_points(i)[4])\n",
    "    \n",
    "    P_value_list.append(average_heartbeats[i][find_points(i)[0]])\n",
    "    Q_value_list.append(average_heartbeats[i][find_points(i)[1]])\n",
    "    S_value_list.append(average_heartbeats[i][find_points(i)[3]])\n",
    "    T_value_list.append(average_heartbeats[i][find_points(i)[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a09622d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5117"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_sqrd = []\n",
    "for i in range(len(rpeaks_list)):\n",
    "    mean_sqrd.append(mean_sqrd_diff(rpeaks_list[i]))\n",
    "len(mean_sqrd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "847881a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-046d8f0228d1>:26: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  QRS_P_list= np.divide(QRS_list, P_list)\n"
     ]
    }
   ],
   "source": [
    "# Find Intervals and Ratios of peaks\n",
    "RR_list = []\n",
    "PR_list = []\n",
    "QRS_list = []\n",
    "ST_list = []\n",
    "\n",
    "def findInterval(i):\n",
    "    if i+1 < len(R_list):\n",
    "        RR_list.append(P_list[i+1]-P_list[i])\n",
    "    PR_list.append(R_list[i]-P_list[i])\n",
    "    QRS_list.append(S_list[i]-Q_list[i])\n",
    "    ST_list.append(T_list[i]-S_list[i])\n",
    "    \n",
    "for i in range(len(P_list)):\n",
    "    findInterval(i)\n",
    "\n",
    "RR_list = np.array(RR_list).reshape(-1,1)\n",
    "QRS_list = np.array(QRS_list).reshape(-1,1)\n",
    "ST_list = np.array(ST_list).reshape(-1,1)\n",
    "P_list = np.array(P_list).reshape(-1,1)\n",
    "R_list = np.array(R_list).reshape(-1,1)\n",
    "S_list = np.array(S_list).reshape(-1,1)\n",
    "T_list = np.array(T_list).reshape(-1,1)\n",
    "\n",
    "QRS_T_list= np.divide(QRS_list, T_list) \n",
    "QRS_P_list= np.divide(QRS_list, P_list) \n",
    "QRS_T_list=np.nan_to_num(QRS_T_list, nan=0.0,posinf=0.0, neginf=0.0)\n",
    "QRS_P_list=np.nan_to_num(QRS_P_list, nan=0.0,posinf=0.0, neginf=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e277a0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_wave = []\n",
    "min_wave = []\n",
    "mean_wave = []\n",
    "median_wave = []\n",
    "\n",
    "for i in range(len(average_heartbeats)):\n",
    "    current = average_heartbeats[i]\n",
    "    max_wave.append(max(current))\n",
    "    min_wave.append(min(current))\n",
    "    mean_wave.append(np.mean(current))\n",
    "    median_wave.append(np.median(current))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "292e0658",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:261: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:221: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:253: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3702: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    }
   ],
   "source": [
    "# Heart rates mean, median, variant and standard deviation\n",
    "hr_mean = []\n",
    "hr_std = []\n",
    "hr_median = []\n",
    "hr_var = []\n",
    "\n",
    "for i in range(len(heart_rate_list)):\n",
    "    d = np.diff(heart_rate_list[i])\n",
    "    hr_mean.append(np.mean(d))\n",
    "    hr_std.append(np.std(d))\n",
    "    hr_median.append(np.median(d))\n",
    "    hr_var.append(np.mean(d)-np.var(d))\n",
    "    \n",
    "hr_mean=np.nan_to_num(hr_mean, nan = 0.0)\n",
    "hr_std=np.nan_to_num(hr_std, nan = 0.0)\n",
    "hr_median=np.nan_to_num(hr_median, nan = 0.0)\n",
    "hr_var=np.nan_to_num(hr_var, nan = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddaa6534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timings of peaks mean, median, variant and standard deviation\n",
    "ts_mean = []\n",
    "ts_std = []\n",
    "ts_median = []\n",
    "ts_var = []\n",
    "\n",
    "for i in range(len(ts_list)):\n",
    "    d =np.diff(ts_list[i])\n",
    "    ts_mean.append(np.mean(d))\n",
    "    ts_std.append(np.std(d))\n",
    "    ts_median.append(np.median(d))\n",
    "    ts_var.append(np.mean(d)-np.var(d))\n",
    "    \n",
    "ts_mean=np.nan_to_num(ts_mean, nan=0.0)\n",
    "ts_std=np.nan_to_num(ts_std, nan=0.0)\n",
    "ts_median=np.nan_to_num(ts_median, nan=0.0)\n",
    "ts_var=np.nan_to_num(ts_var, nan=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efec45ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timings of heart rates mean, median, variant and standard deviation\n",
    "hr_ts_mean = []\n",
    "hr_ts_std = []\n",
    "hr_ts_median = []\n",
    "hr_ts_var = []\n",
    "\n",
    "for i in range(len(heart_rate_ts_list)):\n",
    "    d =np.diff(heart_rate_ts_list[i])\n",
    "    hr_ts_mean.append(np.mean(d))\n",
    "    hr_ts_std.append(np.std(d))\n",
    "    hr_ts_median.append(np.median(d))\n",
    "    hr_ts_var.append(np.mean(d)-np.var(d))\n",
    "    \n",
    "hr_ts_mean=np.nan_to_num(hr_ts_mean, nan=0.0)\n",
    "hr_ts_std=np.nan_to_num(hr_ts_std, nan=0.0)\n",
    "hr_ts_median=np.nan_to_num(hr_ts_median, nan=0.0)\n",
    "hr_ts_var=np.nan_to_num(hr_ts_var, nan=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15db5227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peaks mean, median, variant, mode and standard deviation\n",
    "peaks_mean = []\n",
    "peaks_std = []\n",
    "peaks_median =  []\n",
    "peaks_mode = []\n",
    "peaks_var = []\n",
    "\n",
    "for i in range(len(rpeaks_list)):\n",
    "    peaks_mean.append(np.mean(rpeaks_list[i]))\n",
    "    peaks_std.append(np.std(rpeaks_list[i]))\n",
    "    peaks_median.append(np.median(rpeaks_list[i]))\n",
    "    peaks_mode.append(np.mean(rpeaks_list[i])-stats.mode(rpeaks_list[i])[0])\n",
    "    peaks_var.append(np.var(rpeaks_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c26fccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peaks differences mean, median, variant, mode and standard deviation\n",
    "diff_mean=[]\n",
    "diff_std=[]\n",
    "diff_median=[]\n",
    "diff_mode=[]\n",
    "diff_var = []\n",
    "diff_dev = []\n",
    "\n",
    "for i in range(len(rpeaks_list)):\n",
    "    d = np.diff(rpeaks_list[i])\n",
    "    diff_mean.append(np.mean(d))\n",
    "    diff_std.append(np.std(d))\n",
    "    diff_median.append(np.median(d))\n",
    "    diff_mode.append(np.mean(d)-stats.mode(d)[0])\n",
    "    diff_var.append(np.mean(d)-variance(d))\n",
    "    diff_dev.append(np.mean(d)-pstdev(d))\n",
    "\n",
    "diff_mean=np.nan_to_num(diff_mean, nan=0.0)\n",
    "diff_std=np.nan_to_num(diff_std, nan=0.0)\n",
    "diff_median=np.nan_to_num(diff_median, nan=0.0)\n",
    "diff_mode=np.nan_to_num(diff_mode, nan=0.0)\n",
    "diff_var=np.nan_to_num(diff_var, nan=0.0)\n",
    "diff_dev=np.nan_to_num(diff_dev, nan=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07c82ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Energy of the signal\n",
    "energy_list = []\n",
    "for i in range(len(average_heartbeats)):\n",
    "    energy_list.append(np.sum(average_heartbeats[i] ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "522162d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# db2 coefficients\n",
    "cA_list=[]\n",
    "cD_list=[]\n",
    "\n",
    "for i in range(len(average_heartbeats)):\n",
    "    cA, cD = pywt.dwt(average_heartbeats[i], 'db2', mode='periodic')\n",
    "\n",
    "    cA_list.append(cA)\n",
    "    cD_list.append(cD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea4ba9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5117, 238)\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "hr_mean = np.array(hr_mean).reshape(-1,1)\n",
    "hr_std = np.array(hr_std).reshape(-1,1)\n",
    "hr_median = np.array(hr_median).reshape(-1,1)\n",
    "hr_var = np.array(hr_var).reshape(-1,1)\n",
    "\n",
    "hr_ts_mean = np.array(hr_ts_mean).reshape(-1,1)\n",
    "hr_ts_std = np.array(hr_ts_std).reshape(-1,1)\n",
    "hr_ts_median = np.array(hr_ts_median).reshape(-1,1)\n",
    "hr_ts_var = np.array(hr_ts_var).reshape(-1,1)\n",
    "\n",
    "ts_mean = np.array(ts_mean).reshape(-1,1)\n",
    "ts_std = np.array(ts_std).reshape(-1,1)\n",
    "ts_median = np.array(ts_median).reshape(-1,1)\n",
    "ts_var = np.array(ts_var).reshape(-1,1)\n",
    "\n",
    "peaks_mean = np.array(peaks_mean).reshape(-1,1)\n",
    "peaks_std = np.array(peaks_std).reshape(-1,1)\n",
    "peaks_median = np.array(peaks_median).reshape(-1,1)\n",
    "peaks_mode = np.array(peaks_mode).reshape(-1,1)\n",
    "peaks_var = np.array(peaks_var).reshape(-1,1)\n",
    "\n",
    "diff_mean = np.array(diff_mean).reshape(-1,1)\n",
    "diff_std = np.array(diff_std).reshape(-1,1)\n",
    "diff_median = np.array(diff_median).reshape(-1,1)\n",
    "diff_mode = np.array(diff_mode).reshape(-1,1)\n",
    "diff_var = np.array(diff_var).reshape(-1,1)\n",
    "diff_dev = np.array(diff_dev).reshape(-1,1)\n",
    "\n",
    "max_wave = np.array(max_wave).reshape(-1,1)\n",
    "min_wave = np.array(min_wave).reshape(-1,1)\n",
    "mean_wave = np.array(mean_wave).reshape(-1,1)\n",
    "median_wave = np.array(median_wave).reshape(-1,1)\n",
    "\n",
    "energy_list = np.array(energy_list).reshape(-1,1)\n",
    "# RR_list = np.array(RR_list).reshape(-1,1)\n",
    "PR_list = np.array(PR_list).reshape(-1,1)\n",
    "ST_list = np.array(ST_list).reshape(-1,1)\n",
    "P_list = np.array(P_list).reshape(-1,1)\n",
    "Q_list = np.array(Q_list).reshape(-1,1)\n",
    "R_list = np.array(R_list).reshape(-1,1)\n",
    "S_list = np.array(S_list).reshape(-1,1)\n",
    "T_list = np.array(T_list).reshape(-1,1)\n",
    "\n",
    "mean_sqrd = np.array(mean_sqrd).reshape(-1,1)\n",
    "\n",
    "# Creates array of all training data's features\n",
    "feats_train = np.concatenate((fft,\n",
    "                             autocorr,\n",
    "                             ptp,\n",
    "                             avg,\n",
    "                             peaks_var,\n",
    "                             peaks_mean,\n",
    "                             peaks_std,\n",
    "                             peaks_median,\n",
    "                             peaks_mode,\n",
    "                             P_list,\n",
    "                             Q_list,\n",
    "                             R_list,\n",
    "                             S_list,\n",
    "                             T_list,\n",
    "                             ST_list,\n",
    "                             QRS_list,\n",
    "                             PR_list,\n",
    "                             QRS_T_list,\n",
    "                             max_wave - min_wave,\n",
    "                             mean_wave,\n",
    "                             median_wave,\n",
    "                             hr_std,\n",
    "                             hr_mean,\n",
    "                             hr_std,\n",
    "                             hr_var,\n",
    "                             hr_median,\n",
    "                             hr_ts_mean,\n",
    "                             hr_ts_std,\n",
    "                             hr_ts_median,\n",
    "                             hr_ts_var,\n",
    "                             diff_dev,\n",
    "                             diff_var,\n",
    "                             diff_std,\n",
    "                             diff_mode,\n",
    "                             diff_mean,\n",
    "                             diff_median,\n",
    "                             ts_mean,\n",
    "                             ts_std,\n",
    "                             ts_median,\n",
    "                             ts_var,\n",
    "                             mean_sqrd,\n",
    "                             cD_list,\n",
    "                             cA_list,\n",
    "                             energy_list), axis=1)\n",
    "print(feats_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb0917e",
   "metadata": {},
   "source": [
    "# 2. Classification using Gradient Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e64423f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of F1 scores: 0.8098094796248778\n",
      "Standard deviation of F1 scores: 0.00852296866798561\n"
     ]
    }
   ],
   "source": [
    "x_training = feats_train\n",
    "y_train = np.ravel(y_train)\n",
    "\n",
    "#replacing NaNs with median of columns\n",
    "impute1 = SimpleImputer(strategy = 'median', fill_value = 0)\n",
    "x_training = impute1.fit_transform(x_training)\n",
    "\n",
    "#rescaling data\n",
    "scaler = StandardScaler() \n",
    "scaler.fit(x_training)\n",
    "x_train = scaler.transform(x_training)\n",
    "\n",
    "# clf = GradientBoostingClassifier(learning_rate=0.05, n_estimators=500, max_depth=7, \n",
    "#                                  min_samples_split=60, min_samples_leaf=9, subsample=1.0,\n",
    "#                                  max_features=50, random_state=0)\n",
    "# using best parameter given by GS\n",
    "# max_features from 60 to 50\n",
    "clf = GradientBoostingClassifier(n_estimators = 250, \n",
    "                                       max_depth = 5,\n",
    "                                       learning_rate = 0.1, \n",
    "                                       max_features = 60)\n",
    "scorer_f1 = make_scorer(f1_score, greater_is_better = True, average = 'micro')\n",
    "\n",
    "cv_means = []\n",
    "cv_stds = []\n",
    "\n",
    "# changed to 5-fold\n",
    "for i in np.arange(10):\n",
    "    scores = cross_val_score(estimator = clf,\n",
    "                                 X = x_training,\n",
    "                                 y = y_train,\n",
    "                                 scoring = scorer_f1,\n",
    "                                 cv = KFold(n_splits = 5, shuffle = True))\n",
    "    cv_means.append(np.mean(scores))\n",
    "    cv_stds.append(np.std(scores))\n",
    "\n",
    "print(\"Average of F1 scores:\", np.mean(cv_means))\n",
    "print(\"Standard deviation of F1 scores:\", np.mean(cv_stds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e6734a",
   "metadata": {},
   "source": [
    "# 3. Extracting features from Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf89e743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract frequency domain features: FFT, power, average and autocorrelation\n",
    "# before padding to 9000 points\n",
    "autocorr = []\n",
    "ptp = []\n",
    "avg = []\n",
    "fft = []\n",
    "\n",
    "for i in range(len(x_test)):\n",
    "    # extract i-th single row as a dataframe and drop na values\n",
    "    signal = x_test.loc[i].dropna().to_numpy(dtype='float32')\n",
    "    signal_series = pd.Series(signal)\n",
    "    # extract autocorrelation, average, ptp(max-min)\n",
    "    autocorr.append(signal_series.autocorr(lag=2))\n",
    "    avg.append(np.average(signal))\n",
    "    ptp.append(np.ptp(signal))\n",
    "    f_coefficients = np.fft.fft(signal)\n",
    "    f_coefficients = f_coefficients[0:800]\n",
    "    n = 15\n",
    "    f = f_coefficients.argsort()[-n:][::-1]\n",
    "    fft.append(f)\n",
    "     \n",
    "autocorr = np.transpose(np.array([autocorr]))\n",
    "ptp = np.transpose(np.array([ptp]))\n",
    "avg = np.transpose(np.array([avg]))\n",
    "fft = np.array(fft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e2a309c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-6dabf44f86c3>:79: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  QRS_P_list= np.divide(QRS_list, P_list)\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:261: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:221: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:253: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3702: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3411, 238)\n"
     ]
    }
   ],
   "source": [
    "# Process a raw ECG signal and extract relevant signal features using default parameters\n",
    "# return ts, filtered, rpeaks, templates_ts, heartbeat templates\n",
    "# and heart_rate_ts, heart_rate\n",
    "ts_list = []\n",
    "filtered_list = []\n",
    "rpeaks_list = []\n",
    "templates_ts_list = []\n",
    "templates_list = []\n",
    "heart_rate_ts_list = []\n",
    "heart_rate_list = []\n",
    "\n",
    "for i in range(len(x_test)):\n",
    "# print(i)\n",
    "    ts, filtered, rpeaks, templates_ts, templates, heart_rate_ts, heart_rate = \\\n",
    "        biosppy.signals.ecg.ecg(signal = x_test.loc[i].dropna().to_numpy(dtype='float32'),\n",
    "                                sampling_rate=300.0, show=False)\n",
    "\n",
    "# # Correct R-peak locations to the maximum, introduce some tolerance level\n",
    "#     rpeaks = ecg.correct_rpeaks(signal = x_test.loc[i].dropna().to_numpy(dtype='float32'),\n",
    "#                                 rpeaks = rpeaks, sampling_rate = 300.0,\n",
    "#                                 tol = 0.01)  \n",
    "# # Set heart rates to array of nans if contains no elements, otherwise min and max are not defined\n",
    "#     if len(heart_rate) == 0:\n",
    "#         heart_rate = np.array([np.nan, np.nan])\n",
    "#     if len(heart_rate_ts) == 0:\n",
    "#         heart_rate_ts = np.array([np.nan, np.nan])\n",
    "        \n",
    "    filtered_list.append(filtered)\n",
    "    rpeaks_list.append(rpeaks)\n",
    "    templates_ts_list.append(templates_ts)\n",
    "    templates_list.append(templates)\n",
    "    heart_rate_ts_list.append(heart_rate_ts)\n",
    "    heart_rate_list.append(heart_rate)\n",
    "    ts_list.append(ts)\n",
    "    \n",
    "# Find the average characteristic heartbeat\n",
    "normalized_templates = []\n",
    "average_heartbeats = []\n",
    "for i in range(len(templates_list)):\n",
    "    normalized_templates.append(normalize(templates_list[i]))\n",
    "    average_heartbeats.append(sum(normalized_templates[i])/len(normalized_templates[i]))\n",
    "    \n",
    "# Find P,Q,R,S,T\n",
    "P_list = []\n",
    "Q_list = []\n",
    "R_list = []\n",
    "S_list = []\n",
    "T_list = []\n",
    "\n",
    "for i in range(len(average_heartbeats)):\n",
    "    P_list.append(find_points(i)[0])\n",
    "    Q_list.append(find_points(i)[1])\n",
    "    R_list.append(find_points(i)[2])\n",
    "    S_list.append(find_points(i)[3])\n",
    "    T_list.append(find_points(i)[4])\n",
    "\n",
    "mean_sqrd = []\n",
    "for i in range(len(rpeaks_list)):\n",
    "    mean_sqrd.append(mean_sqrd_diff(rpeaks_list[i]))\n",
    "\n",
    "# Find Intervals and Ratios of peaks\n",
    "RR_list = []\n",
    "PR_list = []\n",
    "QRS_list = []\n",
    "ST_list = []\n",
    "    \n",
    "for i in range(len(P_list)):\n",
    "    findInterval(i)\n",
    "\n",
    "RR_list = np.array(RR_list).reshape(-1,1)\n",
    "QRS_list = np.array(QRS_list).reshape(-1,1)\n",
    "ST_list = np.array(ST_list).reshape(-1,1)\n",
    "P_list = np.array(P_list).reshape(-1,1)\n",
    "R_list = np.array(R_list).reshape(-1,1)\n",
    "S_list = np.array(S_list).reshape(-1,1)\n",
    "T_list = np.array(T_list).reshape(-1,1)\n",
    "\n",
    "QRS_T_list= np.divide(QRS_list, T_list) \n",
    "QRS_P_list= np.divide(QRS_list, P_list) \n",
    "QRS_T_list=np.nan_to_num(QRS_T_list, nan=0.0,posinf=0.0, neginf=0.0)\n",
    "QRS_P_list=np.nan_to_num(QRS_P_list, nan=0.0,posinf=0.0, neginf=0.0)\n",
    "\n",
    "max_wave = []\n",
    "min_wave = []\n",
    "mean_wave = []\n",
    "median_wave = []\n",
    "\n",
    "for i in range(len(average_heartbeats)):\n",
    "    current = average_heartbeats[i]\n",
    "    max_wave.append(max(current))\n",
    "    min_wave.append(min(current))\n",
    "    mean_wave.append(np.mean(current))\n",
    "    median_wave.append(np.median(current))\n",
    "\n",
    "# Heart rates mean, median, variant and standard deviation\n",
    "hr_mean = []\n",
    "hr_std = []\n",
    "hr_median = []\n",
    "hr_var = []\n",
    "\n",
    "for i in range(len(heart_rate_list)):\n",
    "    d = np.diff(heart_rate_list[i])\n",
    "    hr_mean.append(np.mean(d))\n",
    "    hr_std.append(np.std(d))\n",
    "    hr_median.append(np.median(d))\n",
    "    hr_var.append(np.mean(d)-np.var(d))\n",
    "    \n",
    "hr_mean=np.nan_to_num(hr_mean, nan = 0.0)\n",
    "hr_std=np.nan_to_num(hr_std, nan = 0.0)\n",
    "hr_median=np.nan_to_num(hr_median, nan = 0.0)\n",
    "hr_var=np.nan_to_num(hr_var, nan = 0.0)\n",
    "\n",
    "# Timings of peaks mean, median, variant and standard deviation\n",
    "ts_mean = []\n",
    "ts_std = []\n",
    "ts_median = []\n",
    "ts_var = []\n",
    "\n",
    "for i in range(len(ts_list)):\n",
    "    d =np.diff(ts_list[i])\n",
    "    ts_mean.append(np.mean(d))\n",
    "    ts_std.append(np.std(d))\n",
    "    ts_median.append(np.median(d))\n",
    "    ts_var.append(np.mean(d)-np.var(d))\n",
    "    \n",
    "ts_mean=np.nan_to_num(ts_mean, nan=0.0)\n",
    "ts_std=np.nan_to_num(ts_std, nan=0.0)\n",
    "ts_median=np.nan_to_num(ts_median, nan=0.0)\n",
    "ts_var=np.nan_to_num(ts_var, nan=0.0)\n",
    "\n",
    "# Timings of heart rates mean, median, variant and standard deviation\n",
    "hr_ts_mean = []\n",
    "hr_ts_std = []\n",
    "hr_ts_median = []\n",
    "hr_ts_var = []\n",
    "\n",
    "for i in range(len(heart_rate_ts_list)):\n",
    "    d =np.diff(heart_rate_ts_list[i])\n",
    "    hr_ts_mean.append(np.mean(d))\n",
    "    hr_ts_std.append(np.std(d))\n",
    "    hr_ts_median.append(np.median(d))\n",
    "    hr_ts_var.append(np.mean(d)-np.var(d))\n",
    "    \n",
    "hr_ts_mean=np.nan_to_num(hr_ts_mean, nan=0.0)\n",
    "hr_ts_std=np.nan_to_num(hr_ts_std, nan=0.0)\n",
    "hr_ts_median=np.nan_to_num(hr_ts_median, nan=0.0)\n",
    "hr_ts_var=np.nan_to_num(hr_ts_var, nan=0.0)\n",
    "\n",
    "# Peaks mean, median, variant, mode and standard deviation\n",
    "peaks_mean = []\n",
    "peaks_std = []\n",
    "peaks_median =  []\n",
    "peaks_mode = []\n",
    "peaks_var = []\n",
    "\n",
    "for i in range(len(rpeaks_list)):\n",
    "    peaks_mean.append(np.mean(rpeaks_list[i]))\n",
    "    peaks_std.append(np.std(rpeaks_list[i]))\n",
    "    peaks_median.append(np.median(rpeaks_list[i]))\n",
    "    peaks_mode.append(np.mean(rpeaks_list[i])-stats.mode(rpeaks_list[i])[0])\n",
    "    peaks_var.append(np.var(rpeaks_list[i]))\n",
    "\n",
    "# Peaks differences mean, median, variant, mode and standard deviation\n",
    "diff_mean=[]\n",
    "diff_std=[]\n",
    "diff_median=[]\n",
    "diff_mode=[]\n",
    "diff_var = []\n",
    "diff_dev = []\n",
    "\n",
    "for i in range(len(rpeaks_list)):\n",
    "    d = np.diff(rpeaks_list[i])\n",
    "    diff_mean.append(np.mean(d))\n",
    "    diff_std.append(np.std(d))\n",
    "    diff_median.append(np.median(d))\n",
    "    diff_mode.append(np.mean(d)-stats.mode(d)[0])\n",
    "    diff_var.append(np.mean(d)-variance(d))\n",
    "    diff_dev.append(np.mean(d)-pstdev(d))\n",
    "\n",
    "diff_mean=np.nan_to_num(diff_mean, nan=0.0)\n",
    "diff_std=np.nan_to_num(diff_std, nan=0.0)\n",
    "diff_median=np.nan_to_num(diff_median, nan=0.0)\n",
    "diff_mode=np.nan_to_num(diff_mode, nan=0.0)\n",
    "diff_var=np.nan_to_num(diff_var, nan=0.0)\n",
    "diff_dev=np.nan_to_num(diff_dev, nan=0.0)\n",
    "\n",
    "# db2 coefficients\n",
    "cA_list=[]\n",
    "cD_list=[]\n",
    "\n",
    "for i in range(len(average_heartbeats)):\n",
    "    cA, cD = pywt.dwt(average_heartbeats[i], 'db2', mode='periodic')\n",
    "\n",
    "    cA_list.append(cA)\n",
    "    cD_list.append(cD)\n",
    "\n",
    "# Energy of the signal\n",
    "energy_list = []\n",
    "for i in range(len(average_heartbeats)):\n",
    "    energy_list.append(np.sum(average_heartbeats[i] ** 2))\n",
    "\n",
    "# Prepare data\n",
    "hr_mean = np.array(hr_mean).reshape(-1,1)\n",
    "hr_std = np.array(hr_std).reshape(-1,1)\n",
    "hr_median = np.array(hr_median).reshape(-1,1)\n",
    "hr_var = np.array(hr_var).reshape(-1,1)\n",
    "\n",
    "hr_ts_mean = np.array(hr_ts_mean).reshape(-1,1)\n",
    "hr_ts_std = np.array(hr_ts_std).reshape(-1,1)\n",
    "hr_ts_median = np.array(hr_ts_median).reshape(-1,1)\n",
    "hr_ts_var = np.array(hr_ts_var).reshape(-1,1)\n",
    "\n",
    "ts_mean = np.array(ts_mean).reshape(-1,1)\n",
    "ts_std = np.array(ts_std).reshape(-1,1)\n",
    "ts_median = np.array(ts_median).reshape(-1,1)\n",
    "ts_var = np.array(ts_var).reshape(-1,1)\n",
    "\n",
    "peaks_mean = np.array(peaks_mean).reshape(-1,1)\n",
    "peaks_std = np.array(peaks_std).reshape(-1,1)\n",
    "peaks_median = np.array(peaks_median).reshape(-1,1)\n",
    "peaks_mode = np.array(peaks_mode).reshape(-1,1)\n",
    "peaks_var = np.array(peaks_var).reshape(-1,1)\n",
    "\n",
    "diff_mean = np.array(diff_mean).reshape(-1,1)\n",
    "diff_std = np.array(diff_std).reshape(-1,1)\n",
    "diff_median = np.array(diff_median).reshape(-1,1)\n",
    "diff_mode = np.array(diff_mode).reshape(-1,1)\n",
    "diff_var = np.array(diff_var).reshape(-1,1)\n",
    "diff_dev = np.array(diff_dev).reshape(-1,1)\n",
    "\n",
    "max_wave = np.array(max_wave).reshape(-1,1)\n",
    "min_wave = np.array(min_wave).reshape(-1,1)\n",
    "mean_wave = np.array(mean_wave).reshape(-1,1)\n",
    "median_wave = np.array(median_wave).reshape(-1,1)\n",
    "\n",
    "energy_list = np.array(energy_list).reshape(-1,1)\n",
    "# RR_list = np.array(RR_list).reshape(-1,1)\n",
    "PR_list = np.array(PR_list).reshape(-1,1)\n",
    "ST_list = np.array(ST_list).reshape(-1,1)\n",
    "P_list = np.array(P_list).reshape(-1,1)\n",
    "Q_list = np.array(Q_list).reshape(-1,1)\n",
    "R_list = np.array(R_list).reshape(-1,1)\n",
    "S_list = np.array(S_list).reshape(-1,1)\n",
    "T_list = np.array(T_list).reshape(-1,1)\n",
    "\n",
    "mean_sqrd = np.array(mean_sqrd).reshape(-1,1)\n",
    "\n",
    "# Creates array of all testing data's features\n",
    "feats_test = np.concatenate((fft,\n",
    "                             autocorr,\n",
    "                             ptp,\n",
    "                             avg,\n",
    "                             peaks_var,\n",
    "                             peaks_mean,\n",
    "                             peaks_std,\n",
    "                             peaks_median,\n",
    "                             peaks_mode,\n",
    "                             P_list,\n",
    "                             Q_list,\n",
    "                             R_list,\n",
    "                             S_list,\n",
    "                             T_list,\n",
    "                             ST_list,\n",
    "                             QRS_list,\n",
    "                             PR_list,\n",
    "                             QRS_T_list,\n",
    "                             max_wave - min_wave,\n",
    "                             mean_wave,\n",
    "                             median_wave,\n",
    "                             hr_std,\n",
    "                             hr_mean,\n",
    "                             hr_std,\n",
    "                             hr_var,\n",
    "                             hr_median,\n",
    "                             hr_ts_mean,\n",
    "                             hr_ts_std,\n",
    "                             hr_ts_median,\n",
    "                             hr_ts_var,\n",
    "                             diff_dev,\n",
    "                             diff_var,\n",
    "                             diff_std,\n",
    "                             diff_mode,\n",
    "                             diff_mean,\n",
    "                             diff_median,\n",
    "                             ts_mean,\n",
    "                             ts_std,\n",
    "                             ts_median,\n",
    "                             ts_var,\n",
    "                             mean_sqrd,\n",
    "                             cD_list,\n",
    "                             cA_list,\n",
    "                             energy_list), axis=1)\n",
    "print(feats_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0fc637",
   "metadata": {},
   "source": [
    "# 4. Write predictions to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "33ebf96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing NaNs with median of columns\n",
    "impute2 = SimpleImputer(strategy = 'median', fill_value = 0)\n",
    "feats_test = impute2.fit_transform(feats_test)\n",
    "\n",
    "#rescaling data\n",
    "feats_test = scaler.transform(feats_test)\n",
    "\n",
    "clf.fit(x_training, y_train)\n",
    "predictions = clf.predict(feats_test)\n",
    "\n",
    "prediction_results = pd.DataFrame(data = predictions, columns = ['y'])\n",
    "index = [i for i in range(len(prediction_results))]\n",
    "prediction_results.insert(0,\"id\",index)\n",
    "prediction_results.to_csv('task2/result_10.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1c47205d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3406</th>\n",
       "      <td>3406</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3407</th>\n",
       "      <td>3407</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3408</th>\n",
       "      <td>3408</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3409</th>\n",
       "      <td>3409</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3410</th>\n",
       "      <td>3410</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3411 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  y\n",
       "0        0  3\n",
       "1        1  3\n",
       "2        2  2\n",
       "3        3  3\n",
       "4        4  3\n",
       "...    ... ..\n",
       "3406  3406  3\n",
       "3407  3407  3\n",
       "3408  3408  3\n",
       "3409  3409  3\n",
       "3410  3410  3\n",
       "\n",
       "[3411 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b68c38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
